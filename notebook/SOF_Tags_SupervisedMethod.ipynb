{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 6 : Catégorisez automatiquement des questions\n",
    "# <u>C. Méthodes supervisées</u> <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le contexte\n",
    "\n",
    "Afin d'aider les utilisateurs de Stack Overflow dans leur soumission de question, nous devons mettre en place un système de suggestion de tags. Pour celà nous allons nous baser sur les techniques de machine learning capable en fonction du texte saisi par l'utilisateur de déterminer des tags pertinents.\n",
    "\n",
    "Dans ce notebook nous allons essayer des approches supervisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from ast import literal_eval\n",
    "from time import time\n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "import warnings; \n",
    "#warnings.simplefilter('always') \n",
    "warnings.simplefilter('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Chargement des données pré-traitées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos données sont réparties dans 5 fichiers représentant une taille totale de 0,12Go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "#replace NaN by empty string\n",
    "df = df.replace(np.nan, '', regex=True)\n",
    "df['TAGS_P'] = df['TAGS_P'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64432, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BODY</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>TAGS</th>\n",
       "      <th>TITLE_P</th>\n",
       "      <th>BODY_P</th>\n",
       "      <th>TAGS_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Java generics variable &lt;T&gt; value</td>\n",
       "      <td>&lt;p&gt;At the moment I am using the following code...</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;java&gt;&lt;generics&gt;</td>\n",
       "      <td>java gener variabl valu</td>\n",
       "      <td>moment use follow code filter jpa reduc block ...</td>\n",
       "      <td>[java, generics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How a value typed variable is copied when it i...</td>\n",
       "      <td>&lt;blockquote&gt;\\n  &lt;p&gt;Swift's string type is a va...</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;swift&gt;&lt;function&gt;&lt;value-type&gt;</td>\n",
       "      <td>valu type variabl copi pass function hold copi</td>\n",
       "      <td>swift string type valu type creat new string v...</td>\n",
       "      <td>[swift, function, value-type]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Error while waiting for device: The emulator p...</td>\n",
       "      <td>&lt;p&gt;I am a freshman for the development of the ...</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;android&gt;&lt;android-studio&gt;&lt;android-emulator&gt;&lt;avd&gt;</td>\n",
       "      <td>error wait devic emul process avd kill</td>\n",
       "      <td>freshman develop andriod suffer odd question r...</td>\n",
       "      <td>[android, android-studio, android-emulator, avd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gulp-inject not working with gulp-watch</td>\n",
       "      <td>&lt;p&gt;I am using gulp-inject to auto add SASS imp...</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;javascript&gt;&lt;node.js&gt;&lt;npm&gt;&lt;gulp&gt;&lt;gulp-watch&gt;</td>\n",
       "      <td>gulp inject work gulp watch</td>\n",
       "      <td>use gulp inject auto add sass import newli cre...</td>\n",
       "      <td>[javascript, node.js, npm, gulp, gulp-watch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>React - Call function on props change</td>\n",
       "      <td>&lt;p&gt;My TranslationDetail component is passed an...</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;reactjs&gt;&lt;react-router&gt;</td>\n",
       "      <td>react call function prop chang</td>\n",
       "      <td>translationdetail compon pass id upon open bas...</td>\n",
       "      <td>[reactjs, react-router]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE  \\\n",
       "0                   Java generics variable <T> value   \n",
       "1  How a value typed variable is copied when it i...   \n",
       "2  Error while waiting for device: The emulator p...   \n",
       "3            gulp-inject not working with gulp-watch   \n",
       "4              React - Call function on props change   \n",
       "\n",
       "                                                BODY  SCORE  \\\n",
       "0  <p>At the moment I am using the following code...      6   \n",
       "1  <blockquote>\\n  <p>Swift's string type is a va...      6   \n",
       "2  <p>I am a freshman for the development of the ...      6   \n",
       "3  <p>I am using gulp-inject to auto add SASS imp...     10   \n",
       "4  <p>My TranslationDetail component is passed an...     12   \n",
       "\n",
       "                                               TAGS  \\\n",
       "0                                  <java><generics>   \n",
       "1                     <swift><function><value-type>   \n",
       "2  <android><android-studio><android-emulator><avd>   \n",
       "3      <javascript><node.js><npm><gulp><gulp-watch>   \n",
       "4                           <reactjs><react-router>   \n",
       "\n",
       "                                          TITLE_P  \\\n",
       "0                         java gener variabl valu   \n",
       "1  valu type variabl copi pass function hold copi   \n",
       "2          error wait devic emul process avd kill   \n",
       "3                     gulp inject work gulp watch   \n",
       "4                  react call function prop chang   \n",
       "\n",
       "                                              BODY_P  \\\n",
       "0  moment use follow code filter jpa reduc block ...   \n",
       "1  swift string type valu type creat new string v...   \n",
       "2  freshman develop andriod suffer odd question r...   \n",
       "3  use gulp inject auto add sass import newli cre...   \n",
       "4  translationdetail compon pass id upon open bas...   \n",
       "\n",
       "                                             TAGS_P  \n",
       "0                                  [java, generics]  \n",
       "1                     [swift, function, value-type]  \n",
       "2  [android, android-studio, android-emulator, avd]  \n",
       "3      [javascript, node.js, npm, gulp, gulp-watch]  \n",
       "4                           [reactjs, react-router]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transformation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Echantillonage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Travaillons sur un échantillon de 25 000 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample = df.sample(25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gardons 15 000 données pour l'apprentissage'\n",
    "- Et 10 000 pour vérifier la pertinence de  nos modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_learn = df_sample.iloc[10000:, :].copy()\n",
    "df_validation = df_sample.iloc[:10000, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_learn.shape)\n",
    "display(df_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Filtre sur les tags les plus fréquents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque tag on stocke son nombre d'occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "for tags_list in df['TAGS_P']:\n",
    "    counts.update(tags_list)\n",
    "tags_df = pd.DataFrame.from_dict(counts, orient='index')\n",
    "tags_df.reset_index(drop = False, inplace = True)\n",
    "tags_df= tags_df.rename(columns={'index':'tag', 0:'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La structures tags_df contient pour chacun des tags son occurence. <br/>\n",
    "Gardons que les tags qui sont présents dans au moins 50 documents pour l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequent_tags = tags_df[tags_df['count'] > 50]['tag'].tolist()\n",
    "df_learn['TAGS_P'] = df_learn['TAGS_P'].apply(lambda x: [w for w in x if w in frequent_tags] )\n",
    "# On supprime les lignes qui n'ont plus de tags associés (car aucun n'est présent dans la liste frequent_tags)\n",
    "df_learn = df_learn[df_learn.astype(str)['TAGS_P'] != '[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frequent_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nous reste un peu plus de 500 tags différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14538, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_learn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Découpage en jeu entrainement et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_learn['TITLE_P'] + ' ' + df_learn['BODY_P']\n",
    "Y = df_learn['TAGS_P']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gardons 70% des données pour l'entrainement et 30% pour les tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X,Y,test_size = 0.3,random_state = 0, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (10176,)\n",
      "test  (4362,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train\", x_train.shape)\n",
    "print(\"test \",x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préparons également les données non filtrés (tags les plus fréquents) qui nous serviront pour valider et comparer nos modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_validation = df_validation['TITLE_P'] + ' ' + df_validation['BODY_P']\n",
    "y_validation = df_validation['TAGS_P']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cible = Multi labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre variable cible est composée de plusieurs valeurs de tags.<br/>\n",
    "Nous allons transformer nos tags en matrice binaire indiquant la présence ou pas d'un tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes=frequent_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_mlb = mlb.fit_transform(y_train)\n",
    "y_test_mlb = mlb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation des modéles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrivons des méthodes que nous utiliserons pour tester chacun de nos algorithmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "retourne la F-mesure de performance de notre modélisation\n",
    "'''\n",
    "def getClassifierScore(y_true, y_predicted) :\n",
    "    return metrics.f1_score(y_true, y_predicted, average='micro')\n",
    "\n",
    "'''\n",
    "Méthode générique pour faire une recherche sur grille et évaluer le modèle de classification.\n",
    "Affiche les meilleurs paramètres et la précision du modèle.\n",
    "'''\n",
    "def evaluateClassifier(model, extra_param, x_train, y_train, x_test, y_test) :\n",
    "    Kfold = 5\n",
    "    parameters = { \n",
    "              'tfidf__min_df': [5, 10, 15],\n",
    "              'tfidf__max_df': [0.75, 0.85, 0.95],\n",
    "              'tfidf__ngram_range' : [(1,1), (1,2)]\n",
    "             }\n",
    "    parameters.update(extra_param)\n",
    "    classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', OneVsRestClassifier(model))])\n",
    "    \n",
    "    gs_classifier = GridSearchCV(estimator = classifier, param_grid = parameters, cv = Kfold,  n_jobs=-1)\n",
    "    fit = gs_classifier.fit(x_train, y_train)\n",
    "    print(\"Best params :\", gs_classifier.best_params_)\n",
    "    y_pred = gs_classifier.predict(x_test)\n",
    "    print(\"Classification score: {:.2f} % \".format(100*getClassifierScore(y_test,y_pred)))\n",
    "    return gs_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Prédiction de n tags les plus pertinents pour chacun des posts de notre jeu de données (text_data)\n",
    "Se base sur la probabilité de la prédiction pour le choix des tags.\n",
    "'''\n",
    "\n",
    "def predict_tags(clf, text_data, mlabel_bin, num_tags):\n",
    "    t0 = time()\n",
    "    if hasattr(clf, 'decision_function'):\n",
    "        predictions = clf.decision_function(text_data)\n",
    "    elif hasattr(clf, 'predict_proba'):\n",
    "        predictions = clf.predict_proba(text_data)\n",
    "    else :\n",
    "        return None\n",
    "    top_classes= np.argsort(-predictions)[:,:num_tags]\n",
    "    tags_pred = mlabel_bin.classes_[top_classes]\n",
    "    y_predicted_df = pd.DataFrame(index=text_data.index)\n",
    "    y_predicted_df['TAGS_P']=tags_pred.tolist()\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))\n",
    "    return y_predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Méthode permettant d'évaluer la qualité des prédictions en comparant les tags prédits aux tags réels.\n",
    "calcule pour chaque post, le rapport entre le nombre de tags correctement prédits sur le nombre de tags réels.\n",
    "retourne la moyenne de ces rapports.\n",
    "'''\n",
    "def predictionScore(y_true, y_predicted) :\n",
    "    tags_found=[]\n",
    "    for index, row in y_predicted.iterrows():\n",
    "        number_tags_found = 0\n",
    "        for t in row['TAGS_P'] :\n",
    "            if t in y_true.loc[index]['TAGS_P'] :\n",
    "                number_tags_found +=1\n",
    "        tags_found.append(number_tags_found/len(y_true.loc[index]['TAGS_P']))\n",
    "    print(\"Prediction score: {:.2f} % \".format(100*np.mean(tags_found)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'évaluation des modèles, nous partirons sur 5 tags à prédire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_TAGS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 SGD Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modélisation d'un SVM linéaire avec optimisation à l'aide d'une descente de gradient stochastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params : {'clf__estimator__alpha': 1e-05, 'clf__estimator__penalty': 'elasticnet', 'tfidf__max_df': 0.95, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n",
      "Classification score: 49.26 % \n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='log', max_iter=5, tol=None)\n",
    "parameters = {'clf__estimator__alpha': (0.00001, 0.000001), 'clf__estimator__penalty': ('l2', 'elasticnet')}\n",
    "sgd_grid = evaluateClassifier(sgd, parameters, x_train, y_train_mlb, x_test, y_test_mlb )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 4.176s.\n",
      "Prediction score: 77.39 % \n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_tags(sgd_grid, x_test, mlb, NUM_TAGS)\n",
    "y_true = y_test.to_frame()\n",
    "predictionScore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 4.762s.\n",
      "Prediction score: 54.54 % \n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_tags(sgd_grid, x_validation, mlb, NUM_TAGS)\n",
    "y_true = y_validation.to_frame()\n",
    "predictionScore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Essayons maintenant une classification de type bayésienne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class DenseTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params : {'tfidf__max_df': 0.75, 'tfidf__min_df': 15, 'tfidf__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "g_nb = GaussianNB()\n",
    "parameters = { \n",
    "              'tfidf__min_df': [5, 10, 15],\n",
    "              'tfidf__max_df': [0.75, 0.85, 0.95],\n",
    "              'tfidf__ngram_range' : [(1,1), (1,2)]\n",
    "}\n",
    "g_nb_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('to_dense', DenseTransformer()), \n",
    "    ('clf', OneVsRestClassifier(g_nb))])\n",
    "g_nb_grid = GridSearchCV(estimator = g_nb_pipeline, param_grid = parameters, cv = 5,  n_jobs=-1)\n",
    "fit = g_nb_grid.fit(x_train, y_train_mlb)\n",
    "print(\"Best params :\", g_nb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 322.415s.\n",
      "Prediction score: 23.58 % \n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_tags(g_nb_grid, x_test, mlb, NUM_TAGS)\n",
    "y_true = y_test.to_frame()\n",
    "predictionScore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 720.930s.\n",
      "Prediction score: 15.64 % \n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_tags(g_nb_grid, x_validation, mlb, NUM_TAGS)\n",
    "y_true = y_validation.to_frame()\n",
    "predictionScore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Algorithme basé sur les arbres de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params : {'clf__estimator__criterion': 'entropy', 'clf__estimator__max_depth': 2, 'tfidf__max_df': 0.95, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n",
      "Classification score: 53.72 % \n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "parameters = {'clf__estimator__criterion' : ['entropy', 'gini'], \n",
    "              'clf__estimator__max_depth': [1, 2, 3, 4]}\n",
    "dtree_grid = evaluateClassifier(dtree,parameters, x_train, y_train_mlb, x_test, y_test_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 4.152s.\n",
      "Prediction score: 71.03 % \n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_tags(dtree_grid, x_test, mlb, NUM_TAGS)\n",
    "y_true = y_test.to_frame()\n",
    "predictionScore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 8.564s.\n",
      "Prediction score: 50.43 % \n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_tags(dtree_grid, x_validation, mlb, NUM_TAGS)\n",
    "y_true = y_validation.to_frame()\n",
    "predictionScore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Méthode ensembliste parallèle : forêts aléatoires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette modélisation, le GridSearchCV est trop consommateur de ressources et est particulièrement long.\n",
    "Après quelques tests nous avons finalement de ne pas utiliser la recherche sur grille pour cet algorithme surtout que ce n'est pas cet algo qui nous donnait la meilleure fiabilité de prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2486.722s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "rfc = RandomForestClassifier(oob_score = True)\n",
    "rfc_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_df=0.95, min_df=5, ngram_range=(1,1))),\n",
    "    ('to_dense', DenseTransformer()), \n",
    "    ('clf', OneVsRestClassifier(rfc))])\n",
    "rfc_pipeline.fit(x_train, y_train_mlb)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 111.923s.\n",
      "Prediction score: 57.87 % \n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_tags(rfc_pipeline, x_test, mlb, NUM_TAGS)\n",
    "y_true = y_test.to_frame()\n",
    "predictionScore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 238.512s.\n",
      "Prediction score: 40.06 % \n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_tags(rfc_pipeline, x_validation, mlb, NUM_TAGS)\n",
    "y_true = y_validation.to_frame()\n",
    "predictionScore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Méthode ensembliste séquentielle : Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même constat que pour cet algorithme que pour le Random Forest. Nous n'avons pas fait de recherche sur grille en raison du temps de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 4378.358s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "gb  =  GradientBoostingClassifier()\n",
    "gb_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_df=0.95, min_df=5)),\n",
    "    #('to_dense', DenseTransformer()), \n",
    "    ('clf', OneVsRestClassifier(gb))])\n",
    "gb_pipeline.fit(x_train, y_train_mlb)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 4.605s.\n",
      "Prediction score: 67.99 % \n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_tags(gb_pipeline, x_test, mlb, NUM_TAGS)\n",
    "y_true = y_test.to_frame()\n",
    "predictionScore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 10.196s.\n",
      "Prediction score: 48.07 % \n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_tags(gb_pipeline, x_validation, mlb, NUM_TAGS)\n",
    "y_true = y_validation.to_frame()\n",
    "predictionScore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Bilan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on compare l'score mesurée sur les données de validation, nous avons :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèles supervisés\n",
    "\n",
    "\n",
    "|         | Gaussian Naive Bayes    | Decision Tree | SGD       | Random Forest |Gradient Boosting |\n",
    "|---------|:---------------------:|:-------------:|:-----------:|:-----------:|:-------------:|\n",
    "| Scores  |     15.64 %           |    50.43 %     | **54.54 %**    | 40.06 %     |48.07 %        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèles non supervisés\n",
    "\n",
    "\n",
    "|           | LDA        |      NMF   | \n",
    "|:---------:|:----------:|:----------:|\n",
    "| Scores    |    24.65 % |  26.83 %   | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Nous avons la meilleure performance avec les algorithmes supervisés. <br/>\n",
    "L'algorithme SVM linéaire optimisé par une descente de gradient est celui qui donne le meilleur résultat et la meilleure performance en terme de temps d'execution. C'est celui que nous garderons pour l'API finale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_supervised_model = sgd_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Nombre de tags à proposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 tags : done in 5.157s.\n",
      "Prediction score: 50.82 % \n",
      "4 tags : done in 4.360s.\n",
      "Prediction score: 54.86 % \n",
      "5 tags : done in 4.392s.\n",
      "Prediction score: 57.34 % \n",
      "6 tags : done in 4.361s.\n",
      "Prediction score: 59.14 % \n",
      "7 tags : done in 4.281s.\n",
      "Prediction score: 60.43 % \n",
      "8 tags : done in 4.263s.\n",
      "Prediction score: 61.47 % \n"
     ]
    }
   ],
   "source": [
    "num_tags = [3, 4, 5, 6, 7, 8]\n",
    "for n in num_tags :\n",
    "    print(\"{} tags :\".format(n), end=\" \", flush=True) \n",
    "    y_pred = predict_tags(best_supervised_model, x_validation, mlb, n)\n",
    "    y_true = y_validation.to_frame()\n",
    "    predictionScore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ne pas noyer l'utilisateur de tags et avoir un score raisonnable nous allons partir sur une proposition de 7 tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Sauvegarde des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sauve le classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/tags_SGDClassifier.pkl']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(best_supervised_model, './data/tags_SGDClassifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sauve aussi le MultiLabelBinarizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/tags_multiLabelBin.pkl']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mlb, './data/tags_multiLabelBin.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
